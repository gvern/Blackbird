# ğŸ¦… Blackbird

[![Python](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> _Blackbird_ est une plateforme d'agents conversationnels locaux, propulsÃ©e par **Ollama** et conÃ§ue pour fonctionner en local ou en mode serveur HTTP.

---

## ğŸš€ Table des matiÃ¨res

- [PrÃ©sentation](#-prÃ©sentation)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Structure du projet](#structure-du-projet)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
  - [Interface CLI](#interface-cli)
  - [Test unitaire](#test-unitaire)
- [Contribuer](#contribuer)
- [Licence](#licence)

---

## PrÃ©sentation

Blackbird est une plateforme modulable dâ€™agents IA locaux, idÃ©ale pour :

- Prototyper des assistants spÃ©cialisÃ©s (juridique, technique, etc.)
- ExpÃ©rimenter des LLM locaux via **Ollama** (supporte `llama2`, `mistral-7b`, etc.)
- Tester, historiser et orchestrer plusieurs agents

Lâ€™architecture se veut simple, extensible et 100% open source.

---

## FonctionnalitÃ©s

- ğŸ”Œ **Agents plug-and-play** via des configurations YAML
- ğŸ§  **Chargement local de modÃ¨les** (GGUF, `ollama run`)
- ğŸ’¾ **Memory** : historisation des conversations
- ğŸ› ï¸ **Agent Manager** : crÃ©ation, chargement et exÃ©cution dâ€™agents
- ğŸ¨ **Frontend CLI** enrichi par **Rich** ou optionnellement un UI Streamlit
- ğŸ§ª **Tests** prÃªts Ã  lâ€™emploi pour valider lâ€™intÃ©gration LLM

---

## Structure du projet

```bash
Blackbird/
â”œâ”€â”€ main.py                   # Entrypoint CLI
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ core/                     # Modules centraux
â”‚   â”œâ”€â”€ local_model.py        # Wrapper OllamaLocalModel
â”‚   â”œâ”€â”€ agent_manager.py      # Chargement / exÃ©cution dâ€™agents
â”‚   â””â”€â”€ memory.py             # Historique des Ã©changes
â”œâ”€â”€ tests/                    # ScÃ©narios de tests unitaires
â”‚   â””â”€â”€ test_llm.py
â””â”€â”€ models/                   # (Gitignore) ModÃ¨les GGUF locaux
```

---

## Installation

1. **PrÃ©-requis** :
   - Python 3.8+
   - [Ollama CLI](https://ollama.com/docs) (installer et init)  
     ```bash
     brew install ollama
     ollama pull llama2
     ```

2. **Cloner le projet**  
   ```bash
   git clone https://github.com/votre-org/Blackbird.git
   cd Blackbird
   ```

3. **CrÃ©er et activer un venv**  
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```

4. **Installer les dÃ©pendances**  
   ```bash
   pip install -r requirements.txt
   ```

---

## Configuration

- `.gitignore` exclut `models/` et `data/` pour Ã©viter les fichiers volumineux.
- Un exemple de config pour un agent se trouve dans `agents/<agent_name>/config.yaml`.

---

## Usage

### Interface CLI

```bash
python main.py
```

**Exemple** :
```bash
ğŸ¦… Bienvenue dans Blackbird (Ollama)
Vous: Quelle est la capitale de la France ?
ğŸ§  Blackbird: La capitale de la France est Paris.
```  
Taper `exit` ou `quit` pour terminer.

### Test unitaire

```bash
pytest tests/test_llm.py
```  
Le test valide la classe `OllamaLocalModel` via la fonction `query_ollama`.

---

## Contribuer

1. Forkez ce dÃ©pÃ´t
2. CrÃ©ez une branche : `git checkout -b feature/mon-agent`
3. Codez et testez vos changements
4. Ouvrez une Pull Request

Merci Ã  tous les contributeurs ! ğŸ¦…

---

## Licence

Ce projet est sous licence MIT. Consultez le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.
